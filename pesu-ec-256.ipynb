{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":88318,"databundleVersionId":10112483,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\n\n# Function to clean text columns (Lowercase, whitespace, special characters)\n\ndef clean_text_columns(df, columns):\n\n    \"\"\"\n\n    Convert text columns to lowercase, remove unnecessary whitespace, and remove special characters.\n\n\n\n    Parameters:\n\n    df (pd.DataFrame): The DataFrame containing the columns to be cleaned.\n\n    columns (list): List of column names to clean.\n\n\n\n    Returns:\n\n    pd.DataFrame: DataFrame with cleaned text columns.\n\n    \"\"\"\n\n    for col in columns:\n\n        # Convert to lowercase and strip whitespace\n\n        df[col] = df[col].str.lower().str.strip()\n\n\n\n        # Remove extra spaces\n\n        df[col] = df[col].str.replace(r'\\s+', ' ', regex=True)\n\n\n\n        # Remove special characters\n\n        df[col] = df[col].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n\n\n\n    return df\n\n\n\n# Basic preprocessing for both datasets\n\ndef preprocess_data(train, test):\n\n    # Clean 'Utterance' and other basic text preprocessing\n\n    for df in [train, test]:\n\n        # Clean 'Utterance' column\n\n        df['Utterance'] = df['Utterance'].str.strip()\n\n        df['Utterance'] = df['Utterance'].str.replace('\\n', ' ')\n\n\n\n        # Convert timestamps to seconds\n\n        df['start_seconds'] = pd.to_timedelta(df['StartTime']).dt.total_seconds()\n\n        df['end_seconds'] = pd.to_timedelta(df['EndTime']).dt.total_seconds()\n\n        df['utterance_duration'] = df['end_seconds'] - df['start_seconds']\n\n\n\n        # Add text-based features\n\n        df['utterance_length'] = df['Utterance'].str.len()\n\n        df['word_count'] = df['Utterance'].str.split().str.len()\n\n\n\n        # Add dialogue context features\n\n        df['position_in_dialogue'] = df.groupby('Dialogue_ID')['Utterance_ID'].rank()\n\n        df['dialogue_length'] = df.groupby('Dialogue_ID')['Utterance_ID'].transform('count')\n\n        df['relative_position'] = df['position_in_dialogue'] / df['dialogue_length']\n\n\n\n    # Clean the 'Utterance' column by removing unnecessary characters\n\n    text_columns = ['Utterance']\n\n    train = clean_text_columns(train, text_columns)\n\n    test = clean_text_columns(test, text_columns)\n\n\n\n    # Encode sentiment labels (for training)\n\n    label_encoder = LabelEncoder()\n\n    train['Sentiment_Label'] = label_encoder.fit_transform(train['Emotion'])\n\n\n\n    # # One-hot encode 'Speaker' column\n\n    # train = pd.get_dummies(train, columns=['Speaker'])\n\n    # test = pd.get_dummies(test, columns=['Speaker'])\n\n\n\n    # Encode 'Speaker' column with LabelEncoder\n\n    # le = LabelEncoder()\n\n    # all_speakers = pd.concat([train['Speaker'], test['Speaker']]).unique()\n\n    # le.fit(all_speakers)\n\n    train=train.drop('Speaker',axis=1)\n\n    test=test.drop('Speaker',axis=1)\n\n\n\n    return train, test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:15:33.919565Z","iopub.execute_input":"2024-11-11T10:15:33.920112Z","iopub.status.idle":"2024-11-11T10:15:33.938984Z","shell.execute_reply.started":"2024-11-11T10:15:33.920067Z","shell.execute_reply":"2024-11-11T10:15:33.937456Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-2/set_2_train/train_emotion.csv', encoding='ISO-8859-1')\n\ntest=pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-2/set_2_test/test_emotion.csv', encoding='ISO-8859-1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:15:35.869106Z","iopub.execute_input":"2024-11-11T10:15:35.869622Z","iopub.status.idle":"2024-11-11T10:15:35.907780Z","shell.execute_reply.started":"2024-11-11T10:15:35.869579Z","shell.execute_reply":"2024-11-11T10:15:35.906159Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train, test = preprocess_data(train, test)\n\n\n\n# Check the preprocessed data\n\nprint(train.head())\n\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:15:39.307971Z","iopub.execute_input":"2024-11-11T10:15:39.308532Z","iopub.status.idle":"2024-11-11T10:15:39.418142Z","shell.execute_reply.started":"2024-11-11T10:15:39.308483Z","shell.execute_reply":"2024-11-11T10:15:39.416778Z"}},"outputs":[{"name":"stdout","text":"   Sr No.                                          Utterance  Emotion  \\\n0       8  but therell be perhaps 30 people under you so ...  neutral   \n1      12  all right then well have a definite answer for...  neutral   \n2      32                                   can i get a beer  neutral   \n3      40            he was with her when he wrote this poem  neutral   \n4      42    now that ive touched you you seem emptier still  neutral   \n\n   Dialogue_ID  Utterance_ID  Season  Episode     StartTime       EndTime  \\\n0            0             7       8       21  00:16:48,800  00:16:54,514   \n1            0            11       8       21  00:17:05,025  00:17:13,324   \n2            2             8       3        6   0:06:07,367   0:06:08,035   \n3            3             3       3       12  00:10:21,078  00:10:23,496   \n4            3             5       3       12  00:10:26,667  00:10:29,586   \n\n   start_seconds  end_seconds  utterance_duration  utterance_length  \\\n0        49760.0      55474.0              5714.0                85   \n1         6045.0      14344.0              8299.0               132   \n2         7727.0       8395.0               668.0                17   \n3        21678.0      24096.0              2418.0                40   \n4        27267.0      30186.0              2919.0                51   \n\n   word_count  position_in_dialogue  dialogue_length  relative_position  \\\n0          17                   1.0                2                0.5   \n1          26                   2.0                2                1.0   \n2           5                   1.0                1                1.0   \n3           9                   1.0                2                0.5   \n4           9                   2.0                2                1.0   \n\n   Sentiment_Label  \n0                2  \n1                2  \n2                2  \n3                2  \n4                2  \n   Sr No.                                          Utterance  Dialogue_ID  \\\n0      38                                   oh okay i get it            3   \n1      61            what a coincidence i listen in my sleep            5   \n2     133  well im not im not at all surprised they feel ...           13   \n3     137                                          define me           13   \n4     141                                               yeah           14   \n\n   Utterance_ID  Season  Episode     StartTime       EndTime  start_seconds  \\\n0             0       5       15  00:05:59,776  00:06:01,777        60076.0   \n1             7       4       20  00:14:54,059  00:14:57,896        54899.0   \n2             2       1       13  00:19:54,860  00:19:57,111        56000.0   \n3             6       1       13  00:20:21,845  00:20:26,307        23045.0   \n4             1       6        4   0:21:28,474   0:21:29,058        29734.0   \n\n   end_seconds  utterance_duration  utterance_length  word_count  \\\n0       2137.0            -57939.0                19           5   \n1      58736.0              3837.0                41           8   \n2      58251.0              2251.0                58          12   \n3      27507.0              4462.0                10           2   \n4      30318.0               584.0                 5           1   \n\n   position_in_dialogue  dialogue_length  relative_position  \n0                   1.0                1                1.0  \n1                   1.0                1                1.0  \n2                   1.0                2                0.5  \n3                   2.0                2                1.0  \n4                   1.0                1                1.0  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\nimport cv2\n\nimport torch\n\nfrom transformers import AutoTokenizer, AutoModel\n\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport joblib\n\nimport librosa\n\nimport av  # Library for video/audio processing\n\n\n\n# Check GPU availability\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f\"Using device: {device}\")\n\n\n\ndef extract_features_from_dataset(df, video_dir, is_training=True):\n\n    # Initialize BERT model\n\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n    model = AutoModel.from_pretrained('bert-base-uncased').to(device)\n\n    \n\n    # Initialize face detector\n\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    \n\n    # Load or initialize scalers\n\n    if is_training:\n\n        visual_scaler = StandardScaler()\n\n        text_scaler = StandardScaler()\n\n        audio_scaler = StandardScaler()\n\n    else:\n\n        visual_scaler = joblib.load('visual_scaler.pkl')\n\n        text_scaler = joblib.load('text_scaler.pkl')\n\n        audio_scaler = joblib.load('audio_scaler.pkl')\n\n    \n\n    features = {\n\n        'text': [],\n\n        'visual': [],\n\n        'audio': [],\n\n        'metadata': []\n\n    }\n\n    valid_indices = []\n\n    \n\n    print(f\"Starting feature extraction for {len(df)} samples...\")\n\n    \n\n    for i, (index, row) in enumerate(df.iterrows()):\n\n        if i % 10 == 0:\n\n            print(f\"Processing sample {i}/{len(df)}\")\n\n        \n\n        try:\n\n            # Text features with BERT\n\n            inputs = tokenizer(row['Utterance'], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n\n            \n\n            with torch.no_grad():\n\n                outputs = model(**inputs)\n\n                text_features = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n\n            \n\n            # Visual features\n\n            video_path = os.path.join(video_dir, f\"dia{row['Dialogue_ID']}_utt{row['Utterance_ID']}.mp4\")\n\n            cap = cv2.VideoCapture(video_path)\n\n            frame_features = []\n\n            \n\n            fps = cap.get(cv2.CAP_PROP_FPS)\n\n            start_frame = int(row['start_seconds'] * fps)\n\n            end_frame = int(row['end_seconds'] * fps)\n\n            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n\n            \n\n            while cap.isOpened():\n\n                frame_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)\n\n                if frame_pos > end_frame:\n\n                    break\n\n                \n\n                ret, frame = cap.read()\n\n                if not ret:\n\n                    break\n\n\n\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n\n                \n\n                if len(faces) > 0:\n\n                    x, y, w, h = max(faces, key=lambda x: x[2] * x[3])\n\n                    face_roi = gray[y:y+h, x:x+w]\n\n                    face_roi = cv2.resize(face_roi, (64, 64))\n\n                    \n\n                    frame_feat = [\n\n                        np.mean(face_roi),\n\n                        np.std(face_roi),\n\n                        np.max(face_roi),\n\n                        np.min(face_roi),\n\n                    ]\n\n                    edges = cv2.Canny(face_roi, 100, 200)\n\n                    frame_feat.append(np.mean(edges))\n\n                    \n\n                    frame_features.append(frame_feat)\n\n            \n\n            cap.release()\n\n            \n\n            if frame_features:\n\n                frame_features = np.array(frame_features)\n\n                visual_features = np.concatenate([\n\n                    np.mean(frame_features, axis=0),\n\n                    np.std(frame_features, axis=0),\n\n                    np.max(frame_features, axis=0),\n\n                    np.min(frame_features, axis=0)\n\n                ])\n\n            else:\n\n                visual_features = np.zeros(5 * 4)\n\n            \n\n            # Audio features\n\n            container = av.open(video_path)\n\n            audio_stream = next(stream for stream in container.streams if stream.type == 'audio')\n\n            audio_frames = []\n\n            sample_rate = audio_stream.sample_rate\n\n            start_sample = int(row['start_seconds'] * sample_rate)\n\n            end_sample = int(row['end_seconds'] * sample_rate)\n\n            \n\n            for frame in container.decode(audio_stream):\n\n                audio_array = frame.to_ndarray()\n\n                audio_frames.append(audio_array)\n\n            audio = np.concatenate(audio_frames)\n\n\n\n            # Slice audio between start_sample and end_sample\n\n            if len(audio) > start_sample:\n\n                audio_segment = audio[start_sample:end_sample] if len(audio) > end_sample else audio[start_sample:]\n\n            else:\n\n                audio_segment = np.array([])  # Empty segment if audio is shorter than expected\n\n            \n\n            # Calculate audio features if audio_segment is not empty\n\n            if audio_segment.size > 0:\n\n                audio_features = [\n\n                    np.mean(audio_segment),\n\n                    np.std(audio_segment),\n\n                    np.max(audio_segment),\n\n                    np.min(audio_segment),\n\n                    librosa.feature.zero_crossing_rate(audio_segment)[0].mean(),\n\n                    librosa.feature.spectral_centroid(audio_segment, sr=sample_rate)[0].mean(),\n\n                    librosa.feature.mfcc(audio_segment, sr=sample_rate, n_mfcc=20).mean(axis=1).mean()\n\n                ]\n\n            else:\n\n                audio_features = [0] * 7  # Provide default values for missing audio features\n\n            \n\n            # Metadata features\n\n            metadata_features = np.array([\n\n                row['utterance_duration'],\n\n                row['position_in_dialogue'],\n\n                row['relative_position'],\n\n                \n\n            ])\n\n            \n\n            # Append to features\n\n            features['text'].append(text_features)\n\n            features['visual'].append(visual_features)\n\n            features['audio'].append(audio_features)\n\n            features['metadata'].append(metadata_features)\n\n            valid_indices.append(index)\n\n            \n\n        except Exception as e:\n\n            print(f\"Error processing sample {i}: {str(e)}\")\n\n            continue\n\n    \n\n    # Standardize features if training\n\n    for key in features:\n\n        features[key] = np.array(features[key])\n\n        \n\n    if is_training:\n\n        features['visual'] = visual_scaler.fit_transform(features['visual'])\n\n        features['text'] = text_scaler.fit_transform(features['text'])\n\n        features['audio'] = audio_scaler.fit_transform(features['audio'])\n\n        \n\n        # Save scalers\n\n        joblib.dump(visual_scaler, 'visual_scaler.pkl')\n\n        joblib.dump(text_scaler, 'text_scaler.pkl')\n\n        joblib.dump(audio_scaler, 'audio_scaler.pkl')\n\n    else:\n\n        features['visual'] = visual_scaler.transform(features['visual'])\n\n        features['text'] = text_scaler.transform(features['text'])\n\n        features['audio'] = audio_scaler.transform(features['audio'])\n\n    \n\n    return features, valid_indices\n\n\n\n# Run feature extraction\n\nprint(\"Processing training data...\")\n\ntrain_features, train_indices = extract_features_from_dataset(\n\n    train, \n\n    '/kaggle/input/ml-hackathon-ec-campus-set-2/set_2_train/train_data', \n\n    is_training=True\n\n)\n\n\n\nprint(\"\\nProcessing test data...\")\n\ntest_features, test_indices = extract_features_from_dataset(\n\n    test, \n\n    '/kaggle/input/ml-hackathon-ec-campus-set-2/set_2_test/test_data',\n\n    is_training=False\n\n)\n\n\n\n# Save features\n\nnp.save('train_features.npy', train_features, allow_pickle=True)\n\nnp.save('test_features.npy', test_features, allow_pickle=True)\n\nnp.save('train_indices.npy', train_indices, allow_pickle=True)\n\nnp.save('test_indices.npy', test_indices, allow_pickle=True)\n\n\n\n\n\nprint(\"Feature extraction completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:17:06.351121Z","iopub.execute_input":"2024-11-11T10:17:06.351636Z","iopub.status.idle":"2024-11-11T10:22:46.185625Z","shell.execute_reply.started":"2024-11-11T10:17:06.351592Z","shell.execute_reply":"2024-11-11T10:22:46.184156Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nProcessing training data...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting feature extraction for 1000 samples...\nProcessing sample 0/1000\nProcessing sample 10/1000\nProcessing sample 20/1000\nProcessing sample 30/1000\nProcessing sample 40/1000\nProcessing sample 50/1000\nProcessing sample 60/1000\nProcessing sample 70/1000\nProcessing sample 80/1000\nProcessing sample 90/1000\nProcessing sample 100/1000\nProcessing sample 110/1000\nProcessing sample 120/1000\nProcessing sample 130/1000\nProcessing sample 140/1000\nProcessing sample 150/1000\nProcessing sample 160/1000\nProcessing sample 170/1000\nProcessing sample 180/1000\nProcessing sample 190/1000\nProcessing sample 200/1000\nProcessing sample 210/1000\nProcessing sample 220/1000\nProcessing sample 230/1000\nProcessing sample 240/1000\nProcessing sample 250/1000\nProcessing sample 260/1000\nProcessing sample 270/1000\nProcessing sample 280/1000\nProcessing sample 290/1000\nProcessing sample 300/1000\nProcessing sample 310/1000\nProcessing sample 320/1000\nProcessing sample 330/1000\nProcessing sample 340/1000\nProcessing sample 350/1000\nProcessing sample 360/1000\nProcessing sample 370/1000\nProcessing sample 380/1000\nProcessing sample 390/1000\nProcessing sample 400/1000\nProcessing sample 410/1000\nProcessing sample 420/1000\nProcessing sample 430/1000\nProcessing sample 440/1000\nProcessing sample 450/1000\nProcessing sample 460/1000\nProcessing sample 470/1000\nProcessing sample 480/1000\nProcessing sample 490/1000\nProcessing sample 500/1000\nProcessing sample 510/1000\nProcessing sample 520/1000\nProcessing sample 530/1000\nProcessing sample 540/1000\nProcessing sample 550/1000\nProcessing sample 560/1000\nProcessing sample 570/1000\nProcessing sample 580/1000\nProcessing sample 590/1000\nProcessing sample 600/1000\nProcessing sample 610/1000\nProcessing sample 620/1000\nProcessing sample 630/1000\nProcessing sample 640/1000\nProcessing sample 650/1000\nProcessing sample 660/1000\nProcessing sample 670/1000\nProcessing sample 680/1000\nProcessing sample 690/1000\nProcessing sample 700/1000\nProcessing sample 710/1000\nProcessing sample 720/1000\nProcessing sample 730/1000\nProcessing sample 740/1000\nProcessing sample 750/1000\nProcessing sample 760/1000\nProcessing sample 770/1000\nProcessing sample 780/1000\nProcessing sample 790/1000\nProcessing sample 800/1000\nProcessing sample 810/1000\nProcessing sample 820/1000\nProcessing sample 830/1000\nProcessing sample 840/1000\nProcessing sample 850/1000\nProcessing sample 860/1000\nProcessing sample 870/1000\nProcessing sample 880/1000\nProcessing sample 890/1000\nProcessing sample 900/1000\nProcessing sample 910/1000\nProcessing sample 920/1000\nProcessing sample 930/1000\nProcessing sample 990/1000\n\nProcessing test data...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting feature extraction for 100 samples...\nProcessing sample 0/100\nProcessing sample 10/100\nProcessing sample 20/100\nProcessing sample 30/100\nProcessing sample 40/100\nProcessing sample 50/100\nProcessing sample 60/100\nProcessing sample 70/100\nProcessing sample 80/100\nProcessing sample 90/100\nFeature extraction completed!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"y_train = train.iloc[train_indices]['Sentiment_Label'].values\nnp.save('y_train.npy', y_train, allow_pickle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:23:00.924878Z","iopub.execute_input":"2024-11-11T10:23:00.925388Z","iopub.status.idle":"2024-11-11T10:23:00.937613Z","shell.execute_reply.started":"2024-11-11T10:23:00.925346Z","shell.execute_reply":"2024-11-11T10:23:00.936068Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Assuming train_indices and test_indices are correctly defined and loaded\ny_train = np.load('y_train.npy', allow_pickle=True)\ny_test = y_train[test_indices]  # Creating y_test based on indices\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:24:45.375233Z","iopub.execute_input":"2024-11-11T10:24:45.375730Z","iopub.status.idle":"2024-11-11T10:24:45.384320Z","shell.execute_reply.started":"2024-11-11T10:24:45.375684Z","shell.execute_reply":"2024-11-11T10:24:45.382812Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Unique values in y_train:\", np.unique(y_train))\nprint(\"Unique values in y_test:\", np.unique(y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:24:49.571199Z","iopub.execute_input":"2024-11-11T10:24:49.571802Z","iopub.status.idle":"2024-11-11T10:24:49.581637Z","shell.execute_reply.started":"2024-11-11T10:24:49.571734Z","shell.execute_reply":"2024-11-11T10:24:49.580004Z"}},"outputs":[{"name":"stdout","text":"Unique values in y_train: [0 1 2 3 4]\nUnique values in y_test: [0 1 2 3 4]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Map values greater than 2 to the class 2\ny_train = np.where(y_train > 2, 2, y_train)\ny_test = np.where(y_test > 2, 2, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:25:17.356174Z","iopub.execute_input":"2024-11-11T10:25:17.356633Z","iopub.status.idle":"2024-11-11T10:25:17.363849Z","shell.execute_reply.started":"2024-11-11T10:25:17.356594Z","shell.execute_reply":"2024-11-11T10:25:17.362299Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(\"Mapped unique values in y_train:\", np.unique(y_train))\nprint(\"Mapped unique values in y_test:\", np.unique(y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:25:20.063920Z","iopub.execute_input":"2024-11-11T10:25:20.064387Z","iopub.status.idle":"2024-11-11T10:25:20.073823Z","shell.execute_reply.started":"2024-11-11T10:25:20.064347Z","shell.execute_reply":"2024-11-11T10:25:20.072153Z"}},"outputs":[{"name":"stdout","text":"Mapped unique values in y_train: [0 1 2]\nMapped unique values in y_test: [0 1 2]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\n# Load the extracted features\nprint(\"Loading data...\")\ntrain_features = np.load('train_features.npy', allow_pickle=True).item()\ntest_features = np.load('test_features.npy', allow_pickle=True).item()\ntrain_indices = np.load('train_indices.npy', allow_pickle=True)\ntest_indices = np.load('test_indices.npy', allow_pickle=True)\ny_train = np.load('y_train.npy', allow_pickle=True)\ny_test = y_train[test_indices]\n\n# Ensure labels are within the range [0, 4]\ny_train = np.clip(y_train, 0, 4)\ny_test = np.clip(y_test, 0, 4)\n\n# Split the training data\nprint(\"Splitting data...\")\nX_text_train, X_text_val, X_visual_train, X_visual_val, X_metadata_train, X_metadata_val, y_train, y_val = train_test_split(\n    train_features['text'].astype(np.float32), \n    train_features['visual'].astype(np.float32), \n    train_features['metadata'].astype(np.float32), \n    y_train, \n    test_size=0.2, \n    random_state=42\n)\n\n# Create datasets and dataloaders\ntrain_dataset = TensorDataset(\n    torch.from_numpy(X_text_train),\n    torch.from_numpy(X_visual_train),\n    torch.from_numpy(X_metadata_train),\n    torch.from_numpy(y_train)\n)\nval_dataset = TensorDataset(\n    torch.from_numpy(X_text_val),\n    torch.from_numpy(X_visual_val),\n    torch.from_numpy(X_metadata_val),\n    torch.from_numpy(y_val)\n)\ntest_dataset = TensorDataset(\n    torch.from_numpy(test_features['text'].astype(np.float32)),\n    torch.from_numpy(test_features['visual'].astype(np.float32)),\n    torch.from_numpy(test_features['metadata'].astype(np.float32)),\n    torch.from_numpy(y_test)\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Late Fusion Model\nclass LateFusionModel(nn.Module):\n    def __init__(self, input_size_text, input_size_visual, input_size_metadata, hidden_size, num_classes):\n        super().__init__()\n        self.text_encoder = nn.Sequential(\n            nn.Linear(input_size_text, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.visual_encoder = nn.Sequential(\n            nn.Linear(input_size_visual, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.metadata_encoder = nn.Sequential(\n            nn.Linear(input_size_metadata, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.fusion_weights = nn.Parameter(torch.ones(3)/3)\n\n    def forward(self, text, visual, metadata):\n        text_out = self.text_encoder(text)\n        visual_out = self.visual_encoder(visual)\n        metadata_out = self.metadata_encoder(metadata)\n        \n        weights = F.softmax(self.fusion_weights, dim=0)\n        return weights[0] * text_out + weights[1] * visual_out + weights[2] * metadata_out\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Function to train and evaluate model\ndef train_and_evaluate(model, train_loader, val_loader, test_loader, num_epochs=100):\n    print(\"\\nTraining Late Fusion Model...\")\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n    \n    best_val_f1 = 0\n    best_model_state = None\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        \n        for batch_idx, (text, visual, metadata, labels) in enumerate(train_loader):\n            text, visual = text.to(device), visual.to(device)\n            metadata, labels = metadata.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(text, visual, metadata)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        # Validation phase\n        model.eval()\n        val_preds = []\n        val_true = []\n        \n        with torch.no_grad():\n            for text, visual, metadata, labels in val_loader:\n                text, visual = text.to(device), visual.to(device)\n                metadata, labels = metadata.to(device), labels.to(device)\n                \n                outputs = model(text, visual, metadata)\n                preds = torch.argmax(outputs, dim=1)\n                val_preds.extend(preds.cpu().numpy())\n                val_true.extend(labels.cpu().numpy())\n        \n        val_acc = accuracy_score(val_true, val_preds)\n        val_f1 = f1_score(val_true, val_preds, average='macro')\n        \n        # Save best model\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_model_state = model.state_dict()\n            print(f\"New best model saved! F1-score: {val_f1:.4f}\")\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n        print(f\"Average Loss: {running_loss/len(train_loader):.4f}\")\n        print(f\"Validation Accuracy: {val_acc:.4f}, F1-score: {val_f1:.4f}\")\n        print(f\"Fusion Weights: {F.softmax(model.fusion_weights, dim=0).cpu().detach().numpy()}\")\n        print(\"-\" * 50)\n        \n        scheduler.step()\n    \n    # Load best model and evaluate on test set\n    model.load_state_dict(best_model_state)\n    \n    # Test phase\n    model.eval()\n    test_preds = []\n    test_true = []\n    \n    with torch.no_grad():\n        for text, visual, metadata, labels in test_loader:\n            text, visual = text.to(device), visual.to(device)\n            metadata, labels = metadata.to(device), labels.to(device)\n            \n            outputs = model(text, visual, metadata)\n            preds = torch.argmax(outputs, dim=1)\n            test_preds.extend(preds.cpu().numpy())\n            test_true.extend(labels.cpu().numpy())\n    \n    test_acc = accuracy_score(test_true, test_preds)\n    test_f1 = f1_score(test_true, test_preds, average='macro')\n    \n    print(\"\\nFinal Results:\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    print(f\"Test F1-score: {test_f1:.4f}\")\n    print(f\"Final Fusion Weights: {F.softmax(model.fusion_weights, dim=0).cpu().detach().numpy()}\")\n    \n    # Save model\n    torch.save(model.state_dict(), 'final_late_fusion_model.pth')\n    print(\"\\nModel saved to 'final_late_fusion_model.pth'\")\n    \n    return test_acc, test_f1\n\n# Create and train Late Fusion Model with num_classes=5\nmodel = LateFusionModel(\n    input_size_text=train_features['text'].shape[1],\n    input_size_visual=train_features['visual'].shape[1],\n    input_size_metadata=train_features['metadata'].shape[1],\n    hidden_size=256,\n    num_classes=5  # Updated to accommodate all unique labels\n).to(device)\n\n# Train and evaluate\nacc, f1 = train_and_evaluate(model, train_loader, val_loader, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:25:24.079798Z","iopub.execute_input":"2024-11-11T10:25:24.080405Z","iopub.status.idle":"2024-11-11T10:25:44.564713Z","shell.execute_reply.started":"2024-11-11T10:25:24.080358Z","shell.execute_reply":"2024-11-11T10:25:44.563226Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nSplitting data...\nUsing device: cpu\n\nTraining Late Fusion Model...\nNew best model saved! F1-score: 0.1403\nEpoch [1/100]\nAverage Loss: 1.5031\nValidation Accuracy: 0.5400, F1-score: 0.1403\nFusion Weights: [0.33292145 0.3341523  0.33292618]\n--------------------------------------------------\nEpoch [2/100]\nAverage Loss: 1.3605\nValidation Accuracy: 0.5400, F1-score: 0.1403\nFusion Weights: [0.33334538 0.33428612 0.3323685 ]\n--------------------------------------------------\nEpoch [3/100]\nAverage Loss: 1.2866\nValidation Accuracy: 0.5400, F1-score: 0.1403\nFusion Weights: [0.33441737 0.33393323 0.33164942]\n--------------------------------------------------\nNew best model saved! F1-score: 0.1602\nEpoch [4/100]\nAverage Loss: 1.2359\nValidation Accuracy: 0.5450, F1-score: 0.1602\nFusion Weights: [0.33564037 0.3333758  0.33098385]\n--------------------------------------------------\nNew best model saved! F1-score: 0.1896\nEpoch [5/100]\nAverage Loss: 1.1998\nValidation Accuracy: 0.5550, F1-score: 0.1896\nFusion Weights: [0.3370393  0.33272707 0.33023363]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2490\nEpoch [6/100]\nAverage Loss: 1.1707\nValidation Accuracy: 0.5750, F1-score: 0.2490\nFusion Weights: [0.3384531  0.3320702  0.32947665]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2729\nEpoch [7/100]\nAverage Loss: 1.1361\nValidation Accuracy: 0.5800, F1-score: 0.2729\nFusion Weights: [0.339941  0.3313491 0.3287099]\n--------------------------------------------------\nEpoch [8/100]\nAverage Loss: 1.1031\nValidation Accuracy: 0.5750, F1-score: 0.2709\nFusion Weights: [0.341432   0.33062768 0.32794032]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2845\nEpoch [9/100]\nAverage Loss: 1.0773\nValidation Accuracy: 0.5750, F1-score: 0.2845\nFusion Weights: [0.3429708  0.3298361  0.32719314]\n--------------------------------------------------\nEpoch [10/100]\nAverage Loss: 1.0498\nValidation Accuracy: 0.5650, F1-score: 0.2776\nFusion Weights: [0.3444955  0.3290917  0.32641283]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2872\nEpoch [11/100]\nAverage Loss: 1.0207\nValidation Accuracy: 0.5700, F1-score: 0.2872\nFusion Weights: [0.34526175 0.32872933 0.3260089 ]\n--------------------------------------------------\nEpoch [12/100]\nAverage Loss: 1.0044\nValidation Accuracy: 0.5700, F1-score: 0.2872\nFusion Weights: [0.34601083 0.32837886 0.3256103 ]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2962\nEpoch [13/100]\nAverage Loss: 0.9994\nValidation Accuracy: 0.5750, F1-score: 0.2962\nFusion Weights: [0.34676427 0.32801348 0.32522228]\n--------------------------------------------------\nEpoch [14/100]\nAverage Loss: 0.9877\nValidation Accuracy: 0.5700, F1-score: 0.2872\nFusion Weights: [0.34749624 0.32764384 0.32485992]\n--------------------------------------------------\nEpoch [15/100]\nAverage Loss: 0.9720\nValidation Accuracy: 0.5750, F1-score: 0.2962\nFusion Weights: [0.3482311  0.32727665 0.32449228]\n--------------------------------------------------\nEpoch [16/100]\nAverage Loss: 0.9537\nValidation Accuracy: 0.5700, F1-score: 0.2872\nFusion Weights: [0.34893456 0.3269366  0.32412884]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3045\nEpoch [17/100]\nAverage Loss: 0.9407\nValidation Accuracy: 0.5800, F1-score: 0.3045\nFusion Weights: [0.34966612 0.3265738  0.32376006]\n--------------------------------------------------\nEpoch [18/100]\nAverage Loss: 0.9295\nValidation Accuracy: 0.5750, F1-score: 0.2959\nFusion Weights: [0.3503524  0.32624048 0.32340714]\n--------------------------------------------------\nEpoch [19/100]\nAverage Loss: 0.9187\nValidation Accuracy: 0.5750, F1-score: 0.3010\nFusion Weights: [0.35108057 0.3258971  0.3230223 ]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3173\nEpoch [20/100]\nAverage Loss: 0.9088\nValidation Accuracy: 0.5800, F1-score: 0.3173\nFusion Weights: [0.35178667 0.32555225 0.32266104]\n--------------------------------------------------\nEpoch [21/100]\nAverage Loss: 0.8881\nValidation Accuracy: 0.5800, F1-score: 0.3131\nFusion Weights: [0.35213792 0.325382   0.32248008]\n--------------------------------------------------\nEpoch [22/100]\nAverage Loss: 0.8766\nValidation Accuracy: 0.5800, F1-score: 0.3157\nFusion Weights: [0.35248584 0.32521477 0.32229936]\n--------------------------------------------------\nEpoch [23/100]\nAverage Loss: 0.8767\nValidation Accuracy: 0.5800, F1-score: 0.3137\nFusion Weights: [0.3528359  0.32504505 0.32211903]\n--------------------------------------------------\nEpoch [24/100]\nAverage Loss: 0.8634\nValidation Accuracy: 0.5800, F1-score: 0.3132\nFusion Weights: [0.35318813 0.32487613 0.3219357 ]\n--------------------------------------------------\nEpoch [25/100]\nAverage Loss: 0.8665\nValidation Accuracy: 0.5800, F1-score: 0.3132\nFusion Weights: [0.35353607 0.32470614 0.32175773]\n--------------------------------------------------\nEpoch [26/100]\nAverage Loss: 0.8580\nValidation Accuracy: 0.5800, F1-score: 0.3132\nFusion Weights: [0.35388035 0.3245378  0.32158184]\n--------------------------------------------------\nEpoch [27/100]\nAverage Loss: 0.8603\nValidation Accuracy: 0.5800, F1-score: 0.3113\nFusion Weights: [0.3542291  0.32436523 0.32140574]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3282\nEpoch [28/100]\nAverage Loss: 0.8446\nValidation Accuracy: 0.5850, F1-score: 0.3282\nFusion Weights: [0.35455585 0.32420513 0.32123905]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3347\nEpoch [29/100]\nAverage Loss: 0.8344\nValidation Accuracy: 0.5900, F1-score: 0.3347\nFusion Weights: [0.35490006 0.3240393  0.32106066]\n--------------------------------------------------\nEpoch [30/100]\nAverage Loss: 0.8307\nValidation Accuracy: 0.5850, F1-score: 0.3314\nFusion Weights: [0.3552295  0.32387593 0.32089457]\n--------------------------------------------------\nEpoch [31/100]\nAverage Loss: 0.8297\nValidation Accuracy: 0.5850, F1-score: 0.3314\nFusion Weights: [0.3553993  0.32379067 0.32081005]\n--------------------------------------------------\nEpoch [32/100]\nAverage Loss: 0.8227\nValidation Accuracy: 0.5800, F1-score: 0.3292\nFusion Weights: [0.35556322 0.32371244 0.3207244 ]\n--------------------------------------------------\nEpoch [33/100]\nAverage Loss: 0.8151\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35573244 0.3236295  0.32063803]\n--------------------------------------------------\nEpoch [34/100]\nAverage Loss: 0.8145\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35589448 0.32355136 0.32055417]\n--------------------------------------------------\nEpoch [35/100]\nAverage Loss: 0.8006\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35605448 0.32347265 0.3204729 ]\n--------------------------------------------------\nEpoch [36/100]\nAverage Loss: 0.8059\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35621944 0.32339072 0.32038984]\n--------------------------------------------------\nEpoch [37/100]\nAverage Loss: 0.8047\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35638168 0.32331172 0.32030666]\n--------------------------------------------------\nEpoch [38/100]\nAverage Loss: 0.8105\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35654265 0.32323295 0.32022437]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3404\nEpoch [39/100]\nAverage Loss: 0.7928\nValidation Accuracy: 0.5800, F1-score: 0.3404\nFusion Weights: [0.35670635 0.32315117 0.3201425 ]\n--------------------------------------------------\nEpoch [40/100]\nAverage Loss: 0.7927\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35686886 0.3230689  0.3200623 ]\n--------------------------------------------------\nEpoch [41/100]\nAverage Loss: 0.7950\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35694942 0.32302907 0.32002154]\n--------------------------------------------------\nEpoch [42/100]\nAverage Loss: 0.7958\nValidation Accuracy: 0.5750, F1-score: 0.3270\nFusion Weights: [0.35702842 0.32298964 0.31998184]\n--------------------------------------------------\nEpoch [43/100]\nAverage Loss: 0.7971\nValidation Accuracy: 0.5800, F1-score: 0.3404\nFusion Weights: [0.3571084  0.32295233 0.31993932]\n--------------------------------------------------\nEpoch [44/100]\nAverage Loss: 0.7896\nValidation Accuracy: 0.5800, F1-score: 0.3404\nFusion Weights: [0.3571886 0.322913  0.3198984]\n--------------------------------------------------\nEpoch [45/100]\nAverage Loss: 0.7942\nValidation Accuracy: 0.5800, F1-score: 0.3404\nFusion Weights: [0.35726735 0.32287362 0.31985903]\n--------------------------------------------------\nEpoch [46/100]\nAverage Loss: 0.7906\nValidation Accuracy: 0.5750, F1-score: 0.3383\nFusion Weights: [0.3573472  0.32283404 0.3198188 ]\n--------------------------------------------------\nEpoch [47/100]\nAverage Loss: 0.7823\nValidation Accuracy: 0.5750, F1-score: 0.3383\nFusion Weights: [0.35742477 0.32279646 0.3197788 ]\n--------------------------------------------------\nEpoch [48/100]\nAverage Loss: 0.7859\nValidation Accuracy: 0.5750, F1-score: 0.3383\nFusion Weights: [0.3575032  0.32275903 0.31973773]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3463\nEpoch [49/100]\nAverage Loss: 0.7847\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35758206 0.32271954 0.3196983 ]\n--------------------------------------------------\nEpoch [50/100]\nAverage Loss: 0.7737\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35765982 0.32268205 0.31965807]\n--------------------------------------------------\nEpoch [51/100]\nAverage Loss: 0.7744\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.3576985  0.32266316 0.3196383 ]\n--------------------------------------------------\nEpoch [52/100]\nAverage Loss: 0.7772\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.3577374  0.32264432 0.31961825]\n--------------------------------------------------\nEpoch [53/100]\nAverage Loss: 0.7701\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.3577751  0.3226256  0.31959933]\n--------------------------------------------------\nEpoch [54/100]\nAverage Loss: 0.7730\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35781354 0.3226065  0.31957993]\n--------------------------------------------------\nEpoch [55/100]\nAverage Loss: 0.7708\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35785183 0.32258776 0.3195604 ]\n--------------------------------------------------\nEpoch [56/100]\nAverage Loss: 0.7790\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.3578905  0.3225687  0.31954077]\n--------------------------------------------------\nEpoch [57/100]\nAverage Loss: 0.7748\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35792896 0.32254994 0.31952107]\n--------------------------------------------------\nEpoch [58/100]\nAverage Loss: 0.7675\nValidation Accuracy: 0.5800, F1-score: 0.3463\nFusion Weights: [0.35796708 0.32253134 0.31950158]\n--------------------------------------------------\nEpoch [59/100]\nAverage Loss: 0.7729\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35800594 0.32251227 0.31948182]\n--------------------------------------------------\nEpoch [60/100]\nAverage Loss: 0.7740\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3580433  0.32249373 0.31946293]\n--------------------------------------------------\nEpoch [61/100]\nAverage Loss: 0.7649\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.358062   0.3224847  0.31945324]\n--------------------------------------------------\nEpoch [62/100]\nAverage Loss: 0.7670\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3580813  0.3224752  0.31944355]\n--------------------------------------------------\nEpoch [63/100]\nAverage Loss: 0.7645\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35809997 0.322466   0.31943405]\n--------------------------------------------------\nEpoch [64/100]\nAverage Loss: 0.7717\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3581188  0.32245633 0.3194248 ]\n--------------------------------------------------\nEpoch [65/100]\nAverage Loss: 0.7647\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3581376  0.32244697 0.31941542]\n--------------------------------------------------\nEpoch [66/100]\nAverage Loss: 0.7654\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3581564 0.3224375 0.3194061]\n--------------------------------------------------\nEpoch [67/100]\nAverage Loss: 0.7661\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35817522 0.3224281  0.31939676]\n--------------------------------------------------\nEpoch [68/100]\nAverage Loss: 0.7685\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35819358 0.322419   0.3193874 ]\n--------------------------------------------------\nEpoch [69/100]\nAverage Loss: 0.7683\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35821223 0.32240942 0.31937835]\n--------------------------------------------------\nEpoch [70/100]\nAverage Loss: 0.7598\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35823083 0.32240027 0.319369  ]\n--------------------------------------------------\nEpoch [71/100]\nAverage Loss: 0.7614\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3582403  0.32239556 0.31936413]\n--------------------------------------------------\nEpoch [72/100]\nAverage Loss: 0.7654\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35824963 0.32239094 0.31935936]\n--------------------------------------------------\nEpoch [73/100]\nAverage Loss: 0.7679\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35825896 0.32238626 0.3193547 ]\n--------------------------------------------------\nEpoch [74/100]\nAverage Loss: 0.7626\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35826826 0.32238156 0.31935012]\n--------------------------------------------------\nEpoch [75/100]\nAverage Loss: 0.7643\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3582776  0.322377   0.31934547]\n--------------------------------------------------\nEpoch [76/100]\nAverage Loss: 0.7671\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35828662 0.3223726  0.31934088]\n--------------------------------------------------\nEpoch [77/100]\nAverage Loss: 0.7624\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3582959  0.32236803 0.31933618]\n--------------------------------------------------\nEpoch [78/100]\nAverage Loss: 0.7653\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583052  0.3223632  0.31933156]\n--------------------------------------------------\nEpoch [79/100]\nAverage Loss: 0.7550\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35831448 0.32235867 0.31932685]\n--------------------------------------------------\nEpoch [80/100]\nAverage Loss: 0.7647\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583235  0.32235405 0.31932247]\n--------------------------------------------------\nEpoch [81/100]\nAverage Loss: 0.7627\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35832813 0.32235172 0.31932008]\n--------------------------------------------------\nEpoch [82/100]\nAverage Loss: 0.7613\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583326  0.32234964 0.31931782]\n--------------------------------------------------\nEpoch [83/100]\nAverage Loss: 0.7647\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35833713 0.3223474  0.3193155 ]\n--------------------------------------------------\nEpoch [84/100]\nAverage Loss: 0.7584\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583418  0.32234505 0.31931308]\n--------------------------------------------------\nEpoch [85/100]\nAverage Loss: 0.7561\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35834622 0.32234293 0.3193108 ]\n--------------------------------------------------\nEpoch [86/100]\nAverage Loss: 0.7661\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35835072 0.32234085 0.31930846]\n--------------------------------------------------\nEpoch [87/100]\nAverage Loss: 0.7615\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35835525 0.32233858 0.31930614]\n--------------------------------------------------\nEpoch [88/100]\nAverage Loss: 0.7592\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35835978 0.32233635 0.31930384]\n--------------------------------------------------\nEpoch [89/100]\nAverage Loss: 0.7643\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583643  0.32233414 0.31930158]\n--------------------------------------------------\nEpoch [90/100]\nAverage Loss: 0.7593\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35836878 0.32233196 0.3192993 ]\n--------------------------------------------------\nEpoch [91/100]\nAverage Loss: 0.7658\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583711 0.3223308 0.3192981]\n--------------------------------------------------\nEpoch [92/100]\nAverage Loss: 0.7605\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583734  0.32232964 0.31929693]\n--------------------------------------------------\nEpoch [93/100]\nAverage Loss: 0.7607\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35837573 0.32232854 0.31929576]\n--------------------------------------------------\nEpoch [94/100]\nAverage Loss: 0.7615\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.358378   0.32232738 0.3192946 ]\n--------------------------------------------------\nEpoch [95/100]\nAverage Loss: 0.7572\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35838032 0.32232633 0.3192934 ]\n--------------------------------------------------\nEpoch [96/100]\nAverage Loss: 0.7583\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35838252 0.32232517 0.3192923 ]\n--------------------------------------------------\nEpoch [97/100]\nAverage Loss: 0.7629\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35838473 0.32232416 0.31929117]\n--------------------------------------------------\nEpoch [98/100]\nAverage Loss: 0.7700\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35838702 0.322323   0.31928998]\n--------------------------------------------------\nEpoch [99/100]\nAverage Loss: 0.7601\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.3583893  0.32232186 0.31928885]\n--------------------------------------------------\nEpoch [100/100]\nAverage Loss: 0.7649\nValidation Accuracy: 0.5750, F1-score: 0.3429\nFusion Weights: [0.35839152 0.32232073 0.31928772]\n--------------------------------------------------\n\nFinal Results:\nTest Accuracy: 0.4300\nTest F1-score: 0.1689\nFinal Fusion Weights: [0.35839152 0.32232073 0.31928772]\n\nModel saved to 'final_late_fusion_model.pth'\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\n# Load the extracted features\nprint(\"Loading data...\")\ntrain_features = np.load('train_features.npy', allow_pickle=True).item()\ntest_features = np.load('test_features.npy', allow_pickle=True).item()\ntrain_indices = np.load('train_indices.npy', allow_pickle=True)\ntest_indices = np.load('test_indices.npy', allow_pickle=True)\ny_train = np.load('y_train.npy', allow_pickle=True)\ny_test = y_train[test_indices]\n\n# Ensure labels are within the range [0, 4]\ny_train = np.clip(y_train, 0, 4)\ny_test = np.clip(y_test, 0, 4)\n\n# Split the training data\nprint(\"Splitting data...\")\nX_text_train, X_text_val, X_visual_train, X_visual_val, X_metadata_train, X_metadata_val, y_train, y_val = train_test_split(\n    train_features['text'].astype(np.float32), \n    train_features['visual'].astype(np.float32), \n    train_features['metadata'].astype(np.float32), \n    y_train, \n    test_size=0.2, \n    random_state=42\n)\n\n# Create datasets and dataloaders\ntrain_dataset = TensorDataset(\n    torch.from_numpy(X_text_train),\n    torch.from_numpy(X_visual_train),\n    torch.from_numpy(X_metadata_train),\n    torch.from_numpy(y_train)\n)\nval_dataset = TensorDataset(\n    torch.from_numpy(X_text_val),\n    torch.from_numpy(X_visual_val),\n    torch.from_numpy(X_metadata_val),\n    torch.from_numpy(y_val)\n)\ntest_dataset = TensorDataset(\n    torch.from_numpy(test_features['text'].astype(np.float32)),\n    torch.from_numpy(test_features['visual'].astype(np.float32)),\n    torch.from_numpy(test_features['metadata'].astype(np.float32)),\n    torch.from_numpy(y_test)\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Early Fusion Model\nclass EarlyFusionModel(nn.Module):\n    def __init__(self, input_size_text, input_size_visual, input_size_metadata, hidden_size, num_classes):\n        super().__init__()\n        self.text_encoder = nn.Sequential(\n            nn.Linear(input_size_text, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3)\n        )\n        \n        self.visual_encoder = nn.Sequential(\n            nn.Linear(input_size_visual, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3)\n        )\n        \n        self.metadata_encoder = nn.Sequential(\n            nn.Linear(input_size_metadata, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3)\n        )\n        \n        self.fusion = nn.Sequential(\n            nn.Linear(3 * hidden_size, 2 * hidden_size),\n            nn.LayerNorm(2 * hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(2 * hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Linear(hidden_size, num_classes)\n        )\n\n    def forward(self, text, visual, metadata):\n        text_features = self.text_encoder(text)\n        visual_features = self.visual_encoder(visual)\n        metadata_features = self.metadata_encoder(metadata)\n        combined = torch.cat([text_features, visual_features, metadata_features], dim=1)\n        return self.fusion(combined)\n\n# Late Fusion Model\nclass LateFusionModel(nn.Module):\n    def __init__(self, input_size_text, input_size_visual, input_size_metadata, hidden_size, num_classes):\n        super().__init__()\n        self.text_encoder = nn.Sequential(\n            nn.Linear(input_size_text, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.visual_encoder = nn.Sequential(\n            nn.Linear(input_size_visual, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.metadata_encoder = nn.Sequential(\n            nn.Linear(input_size_metadata, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU6(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n        self.fusion_weights = nn.Parameter(torch.ones(3)/3)\n\n    def forward(self, text, visual, metadata):\n        text_out = self.text_encoder(text)\n        visual_out = self.visual_encoder(visual)\n        metadata_out = self.metadata_encoder(metadata)\n        \n        weights = F.softmax(self.fusion_weights, dim=0)\n        return weights[0] * text_out + weights[1] * visual_out + weights[2] * metadata_out\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Function to train and evaluate a model\ndef train_and_evaluate(model_name, model, train_loader, val_loader, test_loader, num_epochs=100):\n    print(f\"\\nTraining {model_name}...\")\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n    \n    best_val_f1 = 0\n    best_model_state = None\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        \n        for batch_idx, (text, visual, metadata, labels) in enumerate(train_loader):\n            text, visual = text.to(device), visual.to(device)\n            metadata, labels = metadata.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(text, visual, metadata)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        # Validation phase\n        model.eval()\n        val_preds = []\n        val_true = []\n        \n        with torch.no_grad():\n            for text, visual, metadata, labels in val_loader:\n                text, visual = text.to(device), visual.to(device)\n                metadata, labels = metadata.to(device), labels.to(device)\n                \n                outputs = model(text, visual, metadata)\n                preds = torch.argmax(outputs, dim=1)\n                val_preds.extend(preds.cpu().numpy())\n                val_true.extend(labels.cpu().numpy())\n        \n        val_acc = accuracy_score(val_true, val_preds)\n        val_f1 = f1_score(val_true, val_preds, average='macro')\n        \n        # Save best model\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_model_state = model.state_dict()\n            print(f\"New best model saved! F1-score: {val_f1:.4f}\")\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n        print(f\"Average Loss: {running_loss/len(train_loader):.4f}\")\n        print(f\"Validation Accuracy: {val_acc:.4f}, F1-score: {val_f1:.4f}\")\n        \n        if isinstance(model, LateFusionModel):\n            print(f\"Fusion Weights: {F.softmax(model.fusion_weights, dim=0).cpu().detach().numpy()}\")\n        print(\"-\" * 50)\n        \n        scheduler.step()\n    \n    # Load best model and evaluate on test set\n    model.load_state_dict(best_model_state)\n    \n    # Test phase\n    model.eval()\n    test_preds = []\n    test_true = []\n    \n    with torch.no_grad():\n        for text, visual, metadata, labels in test_loader:\n            text, visual = text.to(device), visual.to(device)\n            metadata, labels = metadata.to(device), labels.to(device)\n            \n            outputs = model(text, visual, metadata)\n            preds = torch.argmax(outputs, dim=1)\n            test_preds.extend(preds.cpu().numpy())\n            test_true.extend(labels.cpu().numpy())\n    \n    test_acc = accuracy_score(test_true, test_preds)\n    test_f1 = f1_score(test_true, test_preds, average='macro')\n    \n    print(f\"\\n{model_name} Final Results:\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    print(f\"Test F1-score: {test_f1:.4f}\")\n    \n    # Save model\n    torch.save(model.state_dict(), f'final_{model_name.lower().replace(\" \", \"_\")}_model.pth')\n    # print(f\"Model saved to 'final_{model_name.lower().replace(\" \", \"_\")}_model.pth'\")\n    print(f\"Model saved to \\\"final_{model_name.lower().replace(' ', '_')}_model.pth\\\"\")\n\n    return test_acc, test_f1\n\n# Train and evaluate Early Fusion Model\nearly_fusion = EarlyFusionModel(\n    input_size_text=train_features['text'].shape[1],\n    input_size_visual=train_features['visual'].shape[1],\n    input_size_metadata=train_features['metadata'].shape[1],\n    hidden_size=256,\n    num_classes=5  # Adjusted to 5 classes\n).to(device)\n\nearly_acc, early_f1 = train_and_evaluate(\n    \"Early Fusion\", \n    early_fusion, \n    train_loader, \n    val_loader, \n    test_loader\n)\n\n# Train and evaluate Late Fusion Model\nlate_fusion = LateFusionModel(\n    input_size_text=train_features['text'].shape[1],\n    input_size_visual=train_features['visual'].shape[1],\n    input_size_metadata=train_features['metadata'].shape[1],\n    hidden_size=256,\n    num_classes=5  # Adjusted to 5 classes\n).to(device)\n\nlate_acc, late_f1 = train_and_evaluate(\n    \"Late Fusion\", \n    late_fusion, \n    train_loader, \n    val_loader, \n    test_loader\n)\n\n# Compare results\nprint(\"\\nModel Comparison:\")\nprint(f\"Early Fusion - Accuracy: {early_acc:.4f}, F1-score: {early_f1:.4f}\")\nprint(f\"Late Fusion  - Accuracy: {late_acc:.4f}, F1-score: {late_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:26:27.649275Z","iopub.execute_input":"2024-11-11T10:26:27.650085Z","iopub.status.idle":"2024-11-11T10:27:17.799430Z","shell.execute_reply.started":"2024-11-11T10:26:27.650037Z","shell.execute_reply":"2024-11-11T10:27:17.797963Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nSplitting data...\nUsing device: cpu\n\nTraining Early Fusion...\nNew best model saved! F1-score: 0.1403\nEpoch [1/100]\nAverage Loss: 1.4076\nValidation Accuracy: 0.5400, F1-score: 0.1403\n--------------------------------------------------\nEpoch [2/100]\nAverage Loss: 1.3248\nValidation Accuracy: 0.5400, F1-score: 0.1403\n--------------------------------------------------\nNew best model saved! F1-score: 0.1598\nEpoch [3/100]\nAverage Loss: 1.2907\nValidation Accuracy: 0.5450, F1-score: 0.1598\n--------------------------------------------------\nNew best model saved! F1-score: 0.2477\nEpoch [4/100]\nAverage Loss: 1.2380\nValidation Accuracy: 0.5650, F1-score: 0.2477\n--------------------------------------------------\nNew best model saved! F1-score: 0.2959\nEpoch [5/100]\nAverage Loss: 1.1834\nValidation Accuracy: 0.5600, F1-score: 0.2959\n--------------------------------------------------\nNew best model saved! F1-score: 0.3113\nEpoch [6/100]\nAverage Loss: 1.1004\nValidation Accuracy: 0.5750, F1-score: 0.3113\n--------------------------------------------------\nNew best model saved! F1-score: 0.3336\nEpoch [7/100]\nAverage Loss: 1.0459\nValidation Accuracy: 0.5700, F1-score: 0.3336\n--------------------------------------------------\nEpoch [8/100]\nAverage Loss: 0.9768\nValidation Accuracy: 0.5650, F1-score: 0.3180\n--------------------------------------------------\nNew best model saved! F1-score: 0.3739\nEpoch [9/100]\nAverage Loss: 0.9089\nValidation Accuracy: 0.5450, F1-score: 0.3739\n--------------------------------------------------\nNew best model saved! F1-score: 0.3831\nEpoch [10/100]\nAverage Loss: 0.8580\nValidation Accuracy: 0.5550, F1-score: 0.3831\n--------------------------------------------------\nEpoch [11/100]\nAverage Loss: 0.7806\nValidation Accuracy: 0.5450, F1-score: 0.3412\n--------------------------------------------------\nEpoch [12/100]\nAverage Loss: 0.7352\nValidation Accuracy: 0.5500, F1-score: 0.3456\n--------------------------------------------------\nEpoch [13/100]\nAverage Loss: 0.6920\nValidation Accuracy: 0.5500, F1-score: 0.3460\n--------------------------------------------------\nEpoch [14/100]\nAverage Loss: 0.6762\nValidation Accuracy: 0.5500, F1-score: 0.3597\n--------------------------------------------------\nEpoch [15/100]\nAverage Loss: 0.5980\nValidation Accuracy: 0.5650, F1-score: 0.3661\n--------------------------------------------------\nNew best model saved! F1-score: 0.3946\nEpoch [16/100]\nAverage Loss: 0.5890\nValidation Accuracy: 0.5700, F1-score: 0.3946\n--------------------------------------------------\nEpoch [17/100]\nAverage Loss: 0.5437\nValidation Accuracy: 0.5600, F1-score: 0.3908\n--------------------------------------------------\nNew best model saved! F1-score: 0.3966\nEpoch [18/100]\nAverage Loss: 0.5083\nValidation Accuracy: 0.5650, F1-score: 0.3966\n--------------------------------------------------\nEpoch [19/100]\nAverage Loss: 0.4850\nValidation Accuracy: 0.5600, F1-score: 0.3791\n--------------------------------------------------\nEpoch [20/100]\nAverage Loss: 0.4584\nValidation Accuracy: 0.5450, F1-score: 0.3901\n--------------------------------------------------\nEpoch [21/100]\nAverage Loss: 0.4378\nValidation Accuracy: 0.5650, F1-score: 0.3656\n--------------------------------------------------\nNew best model saved! F1-score: 0.4014\nEpoch [22/100]\nAverage Loss: 0.4166\nValidation Accuracy: 0.5600, F1-score: 0.4014\n--------------------------------------------------\nEpoch [23/100]\nAverage Loss: 0.3957\nValidation Accuracy: 0.5550, F1-score: 0.3912\n--------------------------------------------------\nEpoch [24/100]\nAverage Loss: 0.4069\nValidation Accuracy: 0.5650, F1-score: 0.3809\n--------------------------------------------------\nEpoch [25/100]\nAverage Loss: 0.3686\nValidation Accuracy: 0.5550, F1-score: 0.3814\n--------------------------------------------------\nEpoch [26/100]\nAverage Loss: 0.3727\nValidation Accuracy: 0.5600, F1-score: 0.3885\n--------------------------------------------------\nEpoch [27/100]\nAverage Loss: 0.3516\nValidation Accuracy: 0.5700, F1-score: 0.3977\n--------------------------------------------------\nEpoch [28/100]\nAverage Loss: 0.3448\nValidation Accuracy: 0.5650, F1-score: 0.3870\n--------------------------------------------------\nEpoch [29/100]\nAverage Loss: 0.3368\nValidation Accuracy: 0.5650, F1-score: 0.3813\n--------------------------------------------------\nEpoch [30/100]\nAverage Loss: 0.3159\nValidation Accuracy: 0.5550, F1-score: 0.3817\n--------------------------------------------------\nEpoch [31/100]\nAverage Loss: 0.3153\nValidation Accuracy: 0.5650, F1-score: 0.3952\n--------------------------------------------------\nNew best model saved! F1-score: 0.4072\nEpoch [32/100]\nAverage Loss: 0.3050\nValidation Accuracy: 0.5650, F1-score: 0.4072\n--------------------------------------------------\nEpoch [33/100]\nAverage Loss: 0.2929\nValidation Accuracy: 0.5650, F1-score: 0.3876\n--------------------------------------------------\nEpoch [34/100]\nAverage Loss: 0.3089\nValidation Accuracy: 0.5500, F1-score: 0.3704\n--------------------------------------------------\nEpoch [35/100]\nAverage Loss: 0.2921\nValidation Accuracy: 0.5650, F1-score: 0.3910\n--------------------------------------------------\nEpoch [36/100]\nAverage Loss: 0.2862\nValidation Accuracy: 0.5700, F1-score: 0.3989\n--------------------------------------------------\nEpoch [37/100]\nAverage Loss: 0.2774\nValidation Accuracy: 0.5600, F1-score: 0.3841\n--------------------------------------------------\nEpoch [38/100]\nAverage Loss: 0.2766\nValidation Accuracy: 0.5700, F1-score: 0.3922\n--------------------------------------------------\nEpoch [39/100]\nAverage Loss: 0.2752\nValidation Accuracy: 0.5650, F1-score: 0.3914\n--------------------------------------------------\nEpoch [40/100]\nAverage Loss: 0.2778\nValidation Accuracy: 0.5650, F1-score: 0.3894\n--------------------------------------------------\nEpoch [41/100]\nAverage Loss: 0.2688\nValidation Accuracy: 0.5650, F1-score: 0.3921\n--------------------------------------------------\nEpoch [42/100]\nAverage Loss: 0.2739\nValidation Accuracy: 0.5600, F1-score: 0.3928\n--------------------------------------------------\nEpoch [43/100]\nAverage Loss: 0.2661\nValidation Accuracy: 0.5600, F1-score: 0.3928\n--------------------------------------------------\nEpoch [44/100]\nAverage Loss: 0.2554\nValidation Accuracy: 0.5600, F1-score: 0.3916\n--------------------------------------------------\nEpoch [45/100]\nAverage Loss: 0.2434\nValidation Accuracy: 0.5650, F1-score: 0.4005\n--------------------------------------------------\nEpoch [46/100]\nAverage Loss: 0.2660\nValidation Accuracy: 0.5600, F1-score: 0.3933\n--------------------------------------------------\nEpoch [47/100]\nAverage Loss: 0.2375\nValidation Accuracy: 0.5650, F1-score: 0.3915\n--------------------------------------------------\nEpoch [48/100]\nAverage Loss: 0.2466\nValidation Accuracy: 0.5650, F1-score: 0.4005\n--------------------------------------------------\nEpoch [49/100]\nAverage Loss: 0.2347\nValidation Accuracy: 0.5600, F1-score: 0.3921\n--------------------------------------------------\nEpoch [50/100]\nAverage Loss: 0.2604\nValidation Accuracy: 0.5700, F1-score: 0.4032\n--------------------------------------------------\nEpoch [51/100]\nAverage Loss: 0.2465\nValidation Accuracy: 0.5700, F1-score: 0.3987\n--------------------------------------------------\nEpoch [52/100]\nAverage Loss: 0.2356\nValidation Accuracy: 0.5700, F1-score: 0.3987\n--------------------------------------------------\nEpoch [53/100]\nAverage Loss: 0.2412\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [54/100]\nAverage Loss: 0.2316\nValidation Accuracy: 0.5700, F1-score: 0.3970\n--------------------------------------------------\nEpoch [55/100]\nAverage Loss: 0.2455\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [56/100]\nAverage Loss: 0.2341\nValidation Accuracy: 0.5700, F1-score: 0.3938\n--------------------------------------------------\nEpoch [57/100]\nAverage Loss: 0.2464\nValidation Accuracy: 0.5700, F1-score: 0.3975\n--------------------------------------------------\nEpoch [58/100]\nAverage Loss: 0.2399\nValidation Accuracy: 0.5700, F1-score: 0.3975\n--------------------------------------------------\nEpoch [59/100]\nAverage Loss: 0.2315\nValidation Accuracy: 0.5750, F1-score: 0.4059\n--------------------------------------------------\nEpoch [60/100]\nAverage Loss: 0.2475\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [61/100]\nAverage Loss: 0.2423\nValidation Accuracy: 0.5750, F1-score: 0.4059\n--------------------------------------------------\nEpoch [62/100]\nAverage Loss: 0.2448\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [63/100]\nAverage Loss: 0.2342\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [64/100]\nAverage Loss: 0.2201\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [65/100]\nAverage Loss: 0.2424\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [66/100]\nAverage Loss: 0.2429\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [67/100]\nAverage Loss: 0.2247\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [68/100]\nAverage Loss: 0.2405\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [69/100]\nAverage Loss: 0.2349\nValidation Accuracy: 0.5750, F1-score: 0.4054\n--------------------------------------------------\nEpoch [70/100]\nAverage Loss: 0.2210\nValidation Accuracy: 0.5750, F1-score: 0.4049\n--------------------------------------------------\nEpoch [71/100]\nAverage Loss: 0.2396\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [72/100]\nAverage Loss: 0.2187\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [73/100]\nAverage Loss: 0.2456\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [74/100]\nAverage Loss: 0.2442\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [75/100]\nAverage Loss: 0.2280\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [76/100]\nAverage Loss: 0.2268\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [77/100]\nAverage Loss: 0.2159\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [78/100]\nAverage Loss: 0.2393\nValidation Accuracy: 0.5750, F1-score: 0.4049\n--------------------------------------------------\nEpoch [79/100]\nAverage Loss: 0.2331\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [80/100]\nAverage Loss: 0.2312\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [81/100]\nAverage Loss: 0.2269\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [82/100]\nAverage Loss: 0.2197\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [83/100]\nAverage Loss: 0.2269\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [84/100]\nAverage Loss: 0.2288\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [85/100]\nAverage Loss: 0.2394\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [86/100]\nAverage Loss: 0.2161\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [87/100]\nAverage Loss: 0.2354\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [88/100]\nAverage Loss: 0.2396\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [89/100]\nAverage Loss: 0.2238\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [90/100]\nAverage Loss: 0.2264\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [91/100]\nAverage Loss: 0.2277\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [92/100]\nAverage Loss: 0.2071\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [93/100]\nAverage Loss: 0.2333\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [94/100]\nAverage Loss: 0.2148\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [95/100]\nAverage Loss: 0.2308\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [96/100]\nAverage Loss: 0.2316\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [97/100]\nAverage Loss: 0.2112\nValidation Accuracy: 0.5700, F1-score: 0.4022\n--------------------------------------------------\nEpoch [98/100]\nAverage Loss: 0.2303\nValidation Accuracy: 0.5750, F1-score: 0.4049\n--------------------------------------------------\nEpoch [99/100]\nAverage Loss: 0.2334\nValidation Accuracy: 0.5750, F1-score: 0.4049\n--------------------------------------------------\nEpoch [100/100]\nAverage Loss: 0.2286\nValidation Accuracy: 0.5750, F1-score: 0.4049\n--------------------------------------------------\n\nEarly Fusion Final Results:\nTest Accuracy: 0.3800\nTest F1-score: 0.1967\nModel saved to \"final_early_fusion_model.pth\"\n\nTraining Late Fusion...\nNew best model saved! F1-score: 0.1959\nEpoch [1/100]\nAverage Loss: 1.7117\nValidation Accuracy: 0.2350, F1-score: 0.1959\nFusion Weights: [0.33406702 0.33256054 0.3333724 ]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2059\nEpoch [2/100]\nAverage Loss: 1.4880\nValidation Accuracy: 0.5350, F1-score: 0.2059\nFusion Weights: [0.33518234 0.3319138  0.33290383]\n--------------------------------------------------\nEpoch [3/100]\nAverage Loss: 1.3535\nValidation Accuracy: 0.5500, F1-score: 0.1780\nFusion Weights: [0.33640698 0.33136237 0.33223063]\n--------------------------------------------------\nEpoch [4/100]\nAverage Loss: 1.2815\nValidation Accuracy: 0.5500, F1-score: 0.1775\nFusion Weights: [0.33762044 0.33084705 0.33153257]\n--------------------------------------------------\nEpoch [5/100]\nAverage Loss: 1.2371\nValidation Accuracy: 0.5550, F1-score: 0.1926\nFusion Weights: [0.33888087 0.33033213 0.330787  ]\n--------------------------------------------------\nEpoch [6/100]\nAverage Loss: 1.1954\nValidation Accuracy: 0.5500, F1-score: 0.1897\nFusion Weights: [0.3401867  0.32978612 0.33002713]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2562\nEpoch [7/100]\nAverage Loss: 1.1594\nValidation Accuracy: 0.5750, F1-score: 0.2562\nFusion Weights: [0.3416056  0.32916066 0.32923377]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2864\nEpoch [8/100]\nAverage Loss: 1.1276\nValidation Accuracy: 0.5900, F1-score: 0.2864\nFusion Weights: [0.34304243 0.328472   0.32848555]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2867\nEpoch [9/100]\nAverage Loss: 1.1104\nValidation Accuracy: 0.5900, F1-score: 0.2867\nFusion Weights: [0.34449065 0.32778704 0.3277223 ]\n--------------------------------------------------\nEpoch [10/100]\nAverage Loss: 1.0709\nValidation Accuracy: 0.5800, F1-score: 0.2864\nFusion Weights: [0.34597662 0.32706115 0.3269622 ]\n--------------------------------------------------\nEpoch [11/100]\nAverage Loss: 1.0520\nValidation Accuracy: 0.5800, F1-score: 0.2864\nFusion Weights: [0.34671667 0.32668447 0.32659882]\n--------------------------------------------------\nEpoch [12/100]\nAverage Loss: 1.0347\nValidation Accuracy: 0.5800, F1-score: 0.2864\nFusion Weights: [0.3475018  0.32630643 0.32619178]\n--------------------------------------------------\nEpoch [13/100]\nAverage Loss: 1.0150\nValidation Accuracy: 0.5750, F1-score: 0.2845\nFusion Weights: [0.34823143 0.32594818 0.32582045]\n--------------------------------------------------\nEpoch [14/100]\nAverage Loss: 0.9990\nValidation Accuracy: 0.5750, F1-score: 0.2845\nFusion Weights: [0.34897998 0.32558066 0.32543933]\n--------------------------------------------------\nEpoch [15/100]\nAverage Loss: 0.9918\nValidation Accuracy: 0.5650, F1-score: 0.2818\nFusion Weights: [0.34969217 0.3252339  0.3250739 ]\n--------------------------------------------------\nNew best model saved! F1-score: 0.2933\nEpoch [16/100]\nAverage Loss: 0.9771\nValidation Accuracy: 0.5650, F1-score: 0.2933\nFusion Weights: [0.35041675 0.3248741  0.32470912]\n--------------------------------------------------\nEpoch [17/100]\nAverage Loss: 0.9655\nValidation Accuracy: 0.5650, F1-score: 0.2933\nFusion Weights: [0.35117084 0.32449678 0.32433242]\n--------------------------------------------------\nEpoch [18/100]\nAverage Loss: 0.9494\nValidation Accuracy: 0.5650, F1-score: 0.2933\nFusion Weights: [0.3518944  0.3241451  0.32396054]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3183\nEpoch [19/100]\nAverage Loss: 0.9363\nValidation Accuracy: 0.5750, F1-score: 0.3183\nFusion Weights: [0.35262215 0.32378414 0.3235937 ]\n--------------------------------------------------\nEpoch [20/100]\nAverage Loss: 0.9277\nValidation Accuracy: 0.5750, F1-score: 0.3183\nFusion Weights: [0.35335806 0.323413   0.32322893]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3308\nEpoch [21/100]\nAverage Loss: 0.9136\nValidation Accuracy: 0.5800, F1-score: 0.3308\nFusion Weights: [0.3537267  0.32322755 0.32304576]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3481\nEpoch [22/100]\nAverage Loss: 0.9034\nValidation Accuracy: 0.5900, F1-score: 0.3481\nFusion Weights: [0.35408524 0.32304713 0.32286766]\n--------------------------------------------------\nEpoch [23/100]\nAverage Loss: 0.8937\nValidation Accuracy: 0.5850, F1-score: 0.3454\nFusion Weights: [0.3544442  0.32286778 0.32268804]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3565\nEpoch [24/100]\nAverage Loss: 0.8886\nValidation Accuracy: 0.5950, F1-score: 0.3565\nFusion Weights: [0.35480142 0.3226908  0.32250783]\n--------------------------------------------------\nEpoch [25/100]\nAverage Loss: 0.8893\nValidation Accuracy: 0.5850, F1-score: 0.3502\nFusion Weights: [0.35515323 0.3225206  0.32232612]\n--------------------------------------------------\nEpoch [26/100]\nAverage Loss: 0.8835\nValidation Accuracy: 0.5850, F1-score: 0.3481\nFusion Weights: [0.3554973  0.3223469  0.32215577]\n--------------------------------------------------\nEpoch [27/100]\nAverage Loss: 0.8706\nValidation Accuracy: 0.5850, F1-score: 0.3481\nFusion Weights: [0.35585523 0.3221662  0.32197854]\n--------------------------------------------------\nEpoch [28/100]\nAverage Loss: 0.8642\nValidation Accuracy: 0.5850, F1-score: 0.3481\nFusion Weights: [0.35620207 0.32199064 0.32180727]\n--------------------------------------------------\nEpoch [29/100]\nAverage Loss: 0.8574\nValidation Accuracy: 0.5850, F1-score: 0.3475\nFusion Weights: [0.35655472 0.32181588 0.32162938]\n--------------------------------------------------\nEpoch [30/100]\nAverage Loss: 0.8589\nValidation Accuracy: 0.5800, F1-score: 0.3449\nFusion Weights: [0.3569017  0.3216438  0.32145447]\n--------------------------------------------------\nEpoch [31/100]\nAverage Loss: 0.8469\nValidation Accuracy: 0.5800, F1-score: 0.3439\nFusion Weights: [0.35707492 0.32155675 0.3213683 ]\n--------------------------------------------------\nEpoch [32/100]\nAverage Loss: 0.8434\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.3572459  0.32146853 0.32128555]\n--------------------------------------------------\nEpoch [33/100]\nAverage Loss: 0.8410\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.3574185  0.3213829  0.32119864]\n--------------------------------------------------\nEpoch [34/100]\nAverage Loss: 0.8443\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.35758662 0.32129693 0.32111645]\n--------------------------------------------------\nEpoch [35/100]\nAverage Loss: 0.8373\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.35775375 0.32121417 0.32103205]\n--------------------------------------------------\nEpoch [36/100]\nAverage Loss: 0.8251\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.3579211  0.32113156 0.32094735]\n--------------------------------------------------\nEpoch [37/100]\nAverage Loss: 0.8223\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.35808825 0.32104558 0.32086614]\n--------------------------------------------------\nEpoch [38/100]\nAverage Loss: 0.8263\nValidation Accuracy: 0.5850, F1-score: 0.3518\nFusion Weights: [0.3582529  0.32096246 0.32078466]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3627\nEpoch [39/100]\nAverage Loss: 0.8192\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.3584193  0.32087812 0.3207026 ]\n--------------------------------------------------\nEpoch [40/100]\nAverage Loss: 0.8170\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.3585845  0.32079396 0.32062158]\n--------------------------------------------------\nEpoch [41/100]\nAverage Loss: 0.8165\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35866696 0.3207528  0.32058027]\n--------------------------------------------------\nEpoch [42/100]\nAverage Loss: 0.8201\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35874778 0.3207109  0.32054132]\n--------------------------------------------------\nEpoch [43/100]\nAverage Loss: 0.8186\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35883084 0.32066986 0.3204993 ]\n--------------------------------------------------\nEpoch [44/100]\nAverage Loss: 0.8106\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35891166 0.32062986 0.32045856]\n--------------------------------------------------\nEpoch [45/100]\nAverage Loss: 0.8084\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35899073 0.32058972 0.32041955]\n--------------------------------------------------\nEpoch [46/100]\nAverage Loss: 0.8022\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35907328 0.32054815 0.32037863]\n--------------------------------------------------\nEpoch [47/100]\nAverage Loss: 0.8087\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.35915148 0.3205079  0.32034057]\n--------------------------------------------------\nEpoch [48/100]\nAverage Loss: 0.8025\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.3592316 0.3204682 0.3203002]\n--------------------------------------------------\nEpoch [49/100]\nAverage Loss: 0.8005\nValidation Accuracy: 0.5900, F1-score: 0.3627\nFusion Weights: [0.3593115  0.32042804 0.32026044]\n--------------------------------------------------\nEpoch [50/100]\nAverage Loss: 0.8021\nValidation Accuracy: 0.5850, F1-score: 0.3592\nFusion Weights: [0.3593903  0.32038796 0.3202217 ]\n--------------------------------------------------\nEpoch [51/100]\nAverage Loss: 0.7993\nValidation Accuracy: 0.5850, F1-score: 0.3592\nFusion Weights: [0.35942978 0.32036775 0.3202024 ]\n--------------------------------------------------\nEpoch [52/100]\nAverage Loss: 0.7991\nValidation Accuracy: 0.5850, F1-score: 0.3592\nFusion Weights: [0.35946932 0.3203482  0.32018244]\n--------------------------------------------------\nNew best model saved! F1-score: 0.3701\nEpoch [53/100]\nAverage Loss: 0.8042\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35950848 0.32032853 0.320163  ]\n--------------------------------------------------\nEpoch [54/100]\nAverage Loss: 0.8007\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35954747 0.3203088  0.3201437 ]\n--------------------------------------------------\nEpoch [55/100]\nAverage Loss: 0.7978\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35958588 0.32028934 0.32012472]\n--------------------------------------------------\nEpoch [56/100]\nAverage Loss: 0.7955\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35962534 0.32026985 0.32010475]\n--------------------------------------------------\nEpoch [57/100]\nAverage Loss: 0.7914\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35966486 0.32025045 0.32008472]\n--------------------------------------------------\nEpoch [58/100]\nAverage Loss: 0.7954\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3597042  0.32023087 0.32006502]\n--------------------------------------------------\nEpoch [59/100]\nAverage Loss: 0.7987\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35974273 0.32021147 0.32004586]\n--------------------------------------------------\nEpoch [60/100]\nAverage Loss: 0.7881\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35978168 0.32019198 0.3200263 ]\n--------------------------------------------------\nEpoch [61/100]\nAverage Loss: 0.7940\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3598013  0.3201821  0.32001662]\n--------------------------------------------------\nEpoch [62/100]\nAverage Loss: 0.7917\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3598209  0.32017228 0.32000688]\n--------------------------------------------------\nEpoch [63/100]\nAverage Loss: 0.7927\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3598396  0.32016277 0.3199976 ]\n--------------------------------------------------\nEpoch [64/100]\nAverage Loss: 0.7985\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35985896 0.320153   0.31998804]\n--------------------------------------------------\nEpoch [65/100]\nAverage Loss: 0.7902\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35987824 0.3201435  0.3199783 ]\n--------------------------------------------------\nEpoch [66/100]\nAverage Loss: 0.7942\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35989758 0.32013392 0.31996846]\n--------------------------------------------------\nEpoch [67/100]\nAverage Loss: 0.7890\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3599161  0.32012463 0.3199593 ]\n--------------------------------------------------\nEpoch [68/100]\nAverage Loss: 0.7908\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35993513 0.32011506 0.31994978]\n--------------------------------------------------\nEpoch [69/100]\nAverage Loss: 0.7916\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3599539  0.32010552 0.3199406 ]\n--------------------------------------------------\nEpoch [70/100]\nAverage Loss: 0.7886\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3599726  0.32009593 0.31993142]\n--------------------------------------------------\nEpoch [71/100]\nAverage Loss: 0.7894\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3599821  0.32009113 0.3199268 ]\n--------------------------------------------------\nEpoch [72/100]\nAverage Loss: 0.7894\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.35999155 0.32008642 0.31992206]\n--------------------------------------------------\nEpoch [73/100]\nAverage Loss: 0.7850\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3600009  0.3200817  0.31991735]\n--------------------------------------------------\nEpoch [74/100]\nAverage Loss: 0.7932\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36001047 0.32007685 0.31991267]\n--------------------------------------------------\nEpoch [75/100]\nAverage Loss: 0.7839\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3600198  0.32007214 0.31990805]\n--------------------------------------------------\nEpoch [76/100]\nAverage Loss: 0.7862\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36002925 0.32006747 0.31990334]\n--------------------------------------------------\nEpoch [77/100]\nAverage Loss: 0.7828\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36003843 0.32006276 0.31989887]\n--------------------------------------------------\nEpoch [78/100]\nAverage Loss: 0.7837\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3600478  0.32005808 0.31989413]\n--------------------------------------------------\nEpoch [79/100]\nAverage Loss: 0.7896\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3600571  0.32005334 0.31988958]\n--------------------------------------------------\nEpoch [80/100]\nAverage Loss: 0.7893\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36006632 0.32004854 0.3198851 ]\n--------------------------------------------------\nEpoch [81/100]\nAverage Loss: 0.7893\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36007097 0.32004613 0.31988284]\n--------------------------------------------------\nEpoch [82/100]\nAverage Loss: 0.7828\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36007562 0.32004377 0.31988063]\n--------------------------------------------------\nEpoch [83/100]\nAverage Loss: 0.7807\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36008024 0.32004145 0.31987834]\n--------------------------------------------------\nEpoch [84/100]\nAverage Loss: 0.7870\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36008483 0.32003912 0.31987602]\n--------------------------------------------------\nEpoch [85/100]\nAverage Loss: 0.7898\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36008954 0.32003677 0.3198737 ]\n--------------------------------------------------\nEpoch [86/100]\nAverage Loss: 0.7813\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36009422 0.32003444 0.31987137]\n--------------------------------------------------\nEpoch [87/100]\nAverage Loss: 0.7927\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36009887 0.32003218 0.31986898]\n--------------------------------------------------\nEpoch [88/100]\nAverage Loss: 0.7836\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3601035  0.3200298  0.31986666]\n--------------------------------------------------\nEpoch [89/100]\nAverage Loss: 0.7867\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36010808 0.3200275  0.31986442]\n--------------------------------------------------\nEpoch [90/100]\nAverage Loss: 0.7799\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3601127  0.32002512 0.3198622 ]\n--------------------------------------------------\nEpoch [91/100]\nAverage Loss: 0.7802\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36011505 0.32002392 0.319861  ]\n--------------------------------------------------\nEpoch [92/100]\nAverage Loss: 0.7896\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3601174  0.32002276 0.31985983]\n--------------------------------------------------\nEpoch [93/100]\nAverage Loss: 0.7776\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36011982 0.3200216  0.31985864]\n--------------------------------------------------\nEpoch [94/100]\nAverage Loss: 0.7845\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36012217 0.32002044 0.31985748]\n--------------------------------------------------\nEpoch [95/100]\nAverage Loss: 0.7766\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3601245  0.32001922 0.31985632]\n--------------------------------------------------\nEpoch [96/100]\nAverage Loss: 0.7816\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36012673 0.32001802 0.31985527]\n--------------------------------------------------\nEpoch [97/100]\nAverage Loss: 0.7864\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36012897 0.32001692 0.31985417]\n--------------------------------------------------\nEpoch [98/100]\nAverage Loss: 0.7825\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.3601313  0.32001567 0.31985307]\n--------------------------------------------------\nEpoch [99/100]\nAverage Loss: 0.7870\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36013362 0.32001448 0.31985196]\n--------------------------------------------------\nEpoch [100/100]\nAverage Loss: 0.7856\nValidation Accuracy: 0.5900, F1-score: 0.3701\nFusion Weights: [0.36013597 0.3200133  0.31985077]\n--------------------------------------------------\n\nLate Fusion Final Results:\nTest Accuracy: 0.4400\nTest F1-score: 0.1532\nModel saved to \"final_late_fusion_model.pth\"\n\nModel Comparison:\nEarly Fusion - Accuracy: 0.3800, F1-score: 0.1967\nLate Fusion  - Accuracy: 0.4400, F1-score: 0.1532\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"⁠ all_preds = [\"your_prediction\" for i in df['Utterance_ID']]\nall_ids = df[\"Sr No.\"]\nsubmission_df = pd.DataFrame({\n        'Sr No.': all_ids,\n        'Emotion': all_preds\n    })\n    \n# Save the DataFrame to CSV\nsubmission_df.to_csv(\"submission.csv\", index=False) ⁠","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}